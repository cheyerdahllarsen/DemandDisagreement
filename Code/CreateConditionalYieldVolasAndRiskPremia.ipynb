{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjXQVf4sJKuH"
      },
      "source": [
        "We start by importing some libraries that we will use. Note that we prefer using the GPU so make sure the runtime is set to one of the GPU environments. The \"free\" T4 seems sufficient here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d03CMrvzJB-Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMPAkdlDJQly"
      },
      "source": [
        "The first function calculates the yield given the current value of  lt  and  ft . Note that we are using  lt  here instead of  Î±t . This is also utilizing pytorch and works best on the GPU. Comments:\n",
        "\n",
        "Could try to see if we could \"save\" some memmory. It will be quite memory intensive when using automatic differentiation\n",
        "Need to verify that it is correct. I have checked the convergence towards the short rate and it looks fine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b_ZTB-qMJTyV"
      },
      "outputs": [],
      "source": [
        "def getYield(f, l, tau, pars, M, dt, device):\n",
        "    rhoA, rhoB, nu, DEL, kap, lbar, sig_l, muY, sigY = pars\n",
        "\n",
        "    NT = round(tau / dt) #Number of time steps\n",
        "\n",
        "    # Initialize tensors for all paths\n",
        "    ft = f * torch.ones(M, device=device)\n",
        "    lt = l * torch.ones(M, device=device)\n",
        "    DFt = torch.ones(M, device=device)\n",
        "\n",
        "    # Generate random numbers for all paths and time steps\n",
        "    dZ = torch.sqrt(torch.tensor(dt)) * torch.randn(NT, M, device=device)\n",
        "\n",
        "    for i in range(NT):\n",
        "        theta_alp = DEL * (0.5 - ft)\n",
        "        alpt = 1 / (1 + torch.exp(-lt))\n",
        "        phit = ft / (rhoA + nu) + (1 - ft) / (rhoB + nu)\n",
        "        betAt = (rhoA + nu) * phit\n",
        "        betBt = (rhoB + nu) * phit\n",
        "\n",
        "        muft = nu * (alpt * betAt * (1 - ft) - (1 - alpt) * betBt * ft) + (rhoB - rhoA) * ft * (1 - ft) + DEL**2 * (1/2 - ft) * ft * (1 - ft)\n",
        "        sigft = ft * (1 - ft) * DEL\n",
        "        dft = muft * dt + sigft * (dZ[i, :] - theta_alp * dt)\n",
        "        dlt = kap * (lbar - lt) * dt + sig_l * (dZ[i, :] - theta_alp * dt)\n",
        "\n",
        "        lt =lt + dlt  # update l0\n",
        "        ft =ft + dft  # update f0\n",
        "        rbar = muY - sigY**2\n",
        "        r = rbar + rhoA * ft + rhoB * (1 - ft)  + nu * (1 - alpt * betAt - (1 - alpt) * betBt)\n",
        "        DFt *= torch.exp(-r * dt)\n",
        "\n",
        "    B = torch.mean(DFt)\n",
        "    return -torch.log(B) / tau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "27boGQ2EJX6Z"
      },
      "outputs": [],
      "source": [
        "def getYieldandYieldVola(f, alp, tau, pars, M, dt, device):\n",
        "  rhoA, rhoB, nu, DEL, kap, lbar, sig_l, muY, sigY = pars\n",
        "  #Since we are doing autodiff we need to make sure we have enabled autograd\n",
        "  l = - -np.log(1/alp-1)\n",
        "  lt = torch.tensor([l], device=device, requires_grad=True)  # Example value\n",
        "  ft = torch.tensor([f], device=device, requires_grad=True)  # Example value\n",
        "  #Calculating the yield\n",
        "  y = getYield(ft, lt, tau, pars, M, dt, device)\n",
        "  # Compute gradients\n",
        "  y.backward()\n",
        "  sigY = ft.grad.item()*ft*(1-ft)*DEL+lt.grad.item()*sig_l\n",
        "  return y.item(), sigY.item(), ft.grad.item(), lt.grad.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uQExEeAMLxYs"
      },
      "outputs": [],
      "source": [
        "def getShortRate(f, alp, tau, pars):\n",
        "  rhoA, rhoB, nu, DEL, kap, lbar, sig_l, muY, sigY = pars\n",
        "  phiA = 1/(rhoA + nu)\n",
        "  phiB = 1/(rhoB + nu)\n",
        "  phi = f*phiA + (1-f)*phiB\n",
        "  betA = (rhoA+nu)*phi\n",
        "  betB = (rhoB+nu)*phi\n",
        "  bet = alp*betA+(1-alp)*betB\n",
        "  rhot = f*rhoA+(1-f)*rhoB\n",
        "  r = rhot + muY-sigY**2 + nu*(1-bet)\n",
        "  return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8IcsCKF1MMMw"
      },
      "outputs": [],
      "source": [
        "def getShortRateVola(f, alp, tau, pars):\n",
        "  rhoA, rhoB, nu, DEL, kap, lbar, sig_l, muY, sigY = pars\n",
        "  phiA = 1/(rhoA + nu)\n",
        "  phiB = 1/(rhoB + nu)\n",
        "  phi = f*phiA + (1-f)*phiB\n",
        "  betA = (rhoA+nu)*phi\n",
        "  betB = (rhoB+nu)*phi\n",
        "  Delrho = rhoB-rhoA\n",
        "  sigalp = alp*(1-alp)*sig_l\n",
        "  sigf = DEL*f*(1-f)\n",
        "  J = nu*(alp*(rhoA+nu)+(1-alp)*(rhoB+nu))\n",
        "  k = -Delrho-J*(1/(rhoA+nu) - 1/(rhoB+nu))\n",
        "  sigr = nu*Delrho*phi*sigalp + k*sigf\n",
        "  return sigr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK_rOB8EJZ-d"
      },
      "source": [
        "\n",
        "Here we set up the specific environment for PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60QVYAvBJZsK",
        "outputId": "f77fc497-31e8-4dfe-cbcf-6077416ec43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "CUDA available: True\n",
            "GPU name: NVIDIA GeForce RTX 4090\n"
          ]
        }
      ],
      "source": [
        "# Set up device - will use GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Uncomment the line below to force CPU usage if needed\n",
        "# device = torch.device(\"cpu\")\n",
        "print(\"Device:\", device)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lNAhArrTJfsc"
      },
      "outputs": [],
      "source": [
        "DEL = 0.8\n",
        "rhoA = -0.015\n",
        "rhoB = 0.025\n",
        "nu = 0.02\n",
        "kap = 0.01\n",
        "lbar = 0\n",
        "sig_l = 0.1\n",
        "muY = 0.02\n",
        "sigY = 0.033\n",
        "pars = [rhoA , rhoB, nu, DEL, kap, lbar, sig_l, muY, sigY]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TWToWldLJlvk"
      },
      "outputs": [],
      "source": [
        "dt = 1 / 12\n",
        "M = 1000  # M = 500000 in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "KXcqyTliLefb",
        "outputId": "e8cbbfc1-67a0-483b-8abf-3d8243252f90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "taus = [dt, 1, 2, 3, 4, 5, 7, 10]  # Example tau values\n",
        "f_values = np.linspace(0.01, 0.99, 200)  # f values from 0.01 to 0.99\n",
        "alp = 0.5\n",
        "plt.figure(figsize=(10, 6))\n",
        "r_values = []\n",
        "for f in f_values:\n",
        "        r = getShortRate(f, alp, 1, pars)\n",
        "        r_values.append(r)\n",
        "y_values_by_tau = {}\n",
        "BondRetStd_by_tau = {}\n",
        "RxValues_by_tau = {}\n",
        "sigrValues_by_tau = {}\n",
        "sigyValues_by_tau = {}\n",
        "for tau in taus:\n",
        "    y_values = []\n",
        "    bondRet = []\n",
        "    RxValues = []\n",
        "    sigrValues = []\n",
        "    sigyValues = []\n",
        "    for f in f_values:\n",
        "        y, sigy, dydf, dydl = getYieldandYieldVola(f, alp, tau, pars, M, dt, device)\n",
        "        sigr =  getShortRateVola(f, alp, tau, pars)\n",
        "        sigyValues.append(sigy)\n",
        "        sigrValues.append(sigr)\n",
        "        bondStd = tau*np.sqrt(np.sum(sigy**2))\n",
        "        rx = -sigy*tau*DEL*(0.5-f)\n",
        "        RxValues.append(rx)\n",
        "        r = getShortRate(f, alp, tau, pars)\n",
        "        y_values.append(y)\n",
        "        bondRet.append(bondStd)\n",
        "    BondRetStd_by_tau[tau] = bondRet\n",
        "    RxValues_by_tau[tau] = RxValues\n",
        "    sigrValues_by_tau[tau] = sigrValues\n",
        "    sigyValues_by_tau[tau] = sigyValues\n",
        "    # Store the y_values for the current tau\n",
        "    y_values_by_tau[tau] = y_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VH5Y7r6zVWtY",
        "outputId": "e702be0f-b07f-4321-9a25-55dc797e878e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to 'Data/Model Disagreement/TEST_model_data_for_f_plots.npz'\n"
          ]
        }
      ],
      "source": [
        "# Ensure the directory exists\n",
        "os.makedirs('Data/Model Disagreement', exist_ok=True)\n",
        "\n",
        "# Save the data\n",
        "np.savez('Data/Model Disagreement/TEST_model_data_for_f_plots.npz',\n",
        "         pars=pars,\n",
        "         taus=taus,\n",
        "         f_values=f_values,\n",
        "         alp=alp,\n",
        "         BondRetStd_by_tau=BondRetStd_by_tau,\n",
        "         RxValues_by_tau=RxValues_by_tau,\n",
        "         sigrValues_by_tau=sigrValues_by_tau,\n",
        "         sigyValues_by_tau=sigyValues_by_tau,\n",
        "         y_values_by_tau=y_values_by_tau)\n",
        "\n",
        "print(\"Data saved to 'Data/Model Disagreement/TEST_model_data_for_f_plots.npz'\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
